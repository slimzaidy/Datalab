Best strategies:

1.SVMS WITH grid search:
Code 

"""implement the SVM model"""

from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
params_grid = [{'kernel': ['rbf','poly'], 'gamma': [1e-1, 1e-2, 1e-3, 1e-4],
                     'C': [1, 10, 50, 100, 1000]},
                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]
svm_model = GridSearchCV(SVC(), params_grid, cv=5)
svm_model.fit(X_train, y_train)
final_svm_model = svm_model.best_estimator_
svm_pred = final_svm_model.predict(X_test)
print(" SVM Accuracy", metrics.accuracy_score(y_test, svm_pred))


2. Change train size to 0.2

X_train, X_test, y_train, y_test = train_test_split(
    df_to_train[df_to_train.columns[:-1]],
    df_to_train["labels"],
    test_size=0.2,
    shuffle=True
)



3.simple XGBOOST classifier 


import xgboost as xgb
xgb_cl = xgb.XGBClassifier()
xgb_cl.fit(X_train, y_train)
preds = xgb_cl.predict(X_test)
accuracy_score(y_test, preds)


4. XGBOOST classifier  with grid search

import xgboost as xgb
param_grid = {
    "max_depth": [2, 4, 5, 7,8],
    "learning_rate": [0.1, 0.01,0.07,0.05,0.15],
    "gamma": [0, 0.25, 1, 0.2,0.4],
    "reg_lambda": [0, 1, 10],
    "scale_pos_weight": [1, 3, 5],
    "subsample": [0.8],
    "colsample_bytree": [0.5],
}
xgb_cl = xgb.XGBClassifier(objective="binary:logistic")
grid_cv = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3, scoring="roc_auc")
_ = grid_cv.fit(X_train, y_train)



5. XGBOOST Regressor

import xgboost as xgb
xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 10)
xg_reg.fit(X_train,y_train)
preds = xg_reg.predict(X_test)



6.XGBOOST stratified cross validations


from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
import xgboost as xgb
model = xgboost.XGBClassifier()
kfold = StratifiedKFold(n_splits=10, random_state=7)
results = cross_val_score(model, X, Y, cv=kfold)



                    
